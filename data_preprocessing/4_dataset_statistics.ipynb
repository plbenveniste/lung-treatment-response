{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset statistics\n",
    "\n",
    "In this file we compute the statistics of the dataset so that it is used for the writing of the project report. \n",
    "The statistics only concern the clinical data. \n",
    "\n",
    "Author: Pierre-Louis Benveniste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset import\n",
    "\n",
    "Here we load the merged dataset containing both the clinical and the radiomics data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is: (181, 162)\n",
      "The columns of the dataset are:\n",
      " ['sexe', 'age', 'BMI', 'score_charlson', 'OMS', 'tabac', 'tabac_PA', 'tabac_sevre', 'histo', 'T', 'centrale', 'dose_tot', 'etalement', 'vol_GTV', 'vol_PTV', 'vol_ITV', 'couv_PTV', 'BED_10', 'DC', 'DDD', 'cause_DC', 'Date_R_PTV', 'Date_R_homo', 'Date_R_med', 'Date_R_contro', 'Date_R_horspoum', 'Reponse', 'rechute_PTV', 'rechute_homo', 'rechute_med', 'rechute_contro', 'rechute_horspoum', 'delai_fin_DC', 'delai_fin_rechutePTV', 'delai_fin_rechuteHomo', 'delai_fin_rechuteMed', 'delai_fin_rechuteContro', 'delai_fin_rechuteHorspoum', 'follow_up', 'MORPHOLOGICAL_Volume', 'MORPHOLOGICAL_ApproximateVolume', 'MORPHOLOGICAL_voxelsCounting', 'MORPHOLOGICAL_SurfaceArea', 'MORPHOLOGICAL_SurfaceToVolumeRatio', 'MORPHOLOGICAL_Compacity', 'MORPHOLOGICAL_Compactness1', 'MORPHOLOGICAL_Compactness2', 'MORPHOLOGICAL_SphericalDisproportion', 'MORPHOLOGICAL_Sphericity', 'MORPHOLOGICAL_Asphericity', 'MORPHOLOGICAL_CentreOfMassShift', 'MORPHOLOGICAL_Maximum3DDiameter', 'MORPHOLOGICAL_SphereDiameter', 'MORPHOLOGICAL_IntegratedIntensity', 'INTENSITY-BASED_MeanIntensity', 'INTENSITY-BASED_IntensitySkewness', 'INTENSITY-BASED_IntensityKurtosis', 'INTENSITY-BASED_MedianIntensity', 'INTENSITY-BASED_MinimumIntensity', 'INTENSITY-BASED_10thIntensityPercentile', 'INTENSITY-BASED_25thIntensityPercentile', 'INTENSITY-BASED_50thIntensityPercentile', 'INTENSITY-BASED_75thIntensityPercentile', 'INTENSITY-BASED_90thIntensityPercentile', 'INTENSITY-BASED_StandardDeviation', 'INTENSITY-BASED_MaximumIntensity', 'INTENSITY-BASED_IntensityInterquartileRange', 'INTENSITY-BASED_IntensityRange', 'INTENSITY-BASED_IntensityBasedMeanAbsoluteDeviation', 'INTENSITY-BASED_IntensityBasedRobustMeanAbsoluteDeviation', 'INTENSITY-BASED_IntensityBasedMedianAbsoluteDeviation', 'INTENSITY-BASED_AreaUnderCurveCIVH', 'INTENSITY-BASED_IntensityBasedEnergy', 'INTENSITY-BASED_RootMeanSquareIntensity', 'INTENSITY-BASED_TotalLesionGlycolysis', 'INTENSITY-HISTOGRAM_IntensityHistogramMean', 'INTENSITY-HISTOGRAM_IntensityHistogramVariance', 'INTENSITY-HISTOGRAM_IntensityHistogramSkewness', 'INTENSITY-HISTOGRAM_IntensityHistogramKurtosis', 'INTENSITY-HISTOGRAM_IntensityHistogramMedian', 'INTENSITY-HISTOGRAM_IntensityHistogramMinimumGreyLevel', 'INTENSITY-HISTOGRAM_IntensityHistogram10thPercentile', 'INTENSITY-HISTOGRAM_IntensityHistogram25thPercentile', 'INTENSITY-HISTOGRAM_IntensityHistogram50thPercentile', 'INTENSITY-HISTOGRAM_IntensityHistogram75thPercentile', 'INTENSITY-HISTOGRAM_IntensityHistogram90thPercentile', 'INTENSITY-HISTOGRAM_IntensityHistogramStd', 'INTENSITY-HISTOGRAM_IntensityHistogramMaximumGreyLevel', 'INTENSITY-HISTOGRAM_IntensityHistogramMode', 'INTENSITY-HISTOGRAM_IntensityHistogramInterquartileRange', 'INTENSITY-HISTOGRAM_IntensityHistogramRange', 'INTENSITY-HISTOGRAM_IntensityHistogramMeanAbsoluteDeviation', 'INTENSITY-HISTOGRAM_IntensityHistogramRobustMeanAbsoluteDeviation', 'INTENSITY-HISTOGRAM_IntensityHistogramMedianAbsoluteDeviation', 'INTENSITY-HISTOGRAM_IntensityHistogramCoefficientOfVariation', 'INTENSITY-HISTOGRAM_IntensityHistogramQuartileCoefficientOfDispersion', 'INTENSITY-HISTOGRAM_IntensityHistogramEntropyLog10', 'INTENSITY-HISTOGRAM_IntensityHistogramEntropyLog2', 'INTENSITY-HISTOGRAM_AreaUnderCurveCIVH', 'INTENSITY-HISTOGRAM_Uniformity', 'INTENSITY-HISTOGRAM_RootMeanSquare', 'INTENSITY-HISTOGRAM_MaximumHistogramGradient', 'INTENSITY-HISTOGRAM_MaximumHistogramGradientGreyLevel', 'INTENSITY-HISTOGRAM_MinimumHistogramGradient', 'INTENSITY-HISTOGRAM_MinimumHistogramGradientGreyLevel', 'GLCM_JointMaximum', 'GLCM_JointAverage', 'GLCM_JointVariance', 'GLCM_JointEntropyLog2', 'GLCM_JointEntropyLog10', 'GLCM_DifferenceAverage', 'GLCM_DifferenceVariance', 'GLCM_SumAverage', 'GLCM_SumVariance', 'GLCM_AngularSecondMoment', 'GLCM_Contrast', 'GLCM_Dissimilarity', 'GLCM_InverseDifference', 'GLCM_NormalisedInverseDifference', 'GLCM_InverseDifferenceMoment', 'GLCM_NormalisedInverseDifferenceMoment', 'GLCM_InverseVariance', 'GLCM_Correlation', 'GLCM_Autocorrelation', 'GLCM_ClusterTendency', 'GLCM_ClusterShade', 'GLCM_ClusterProminence', 'GLRLM_ShortRunsEmphasis', 'GLRLM_LongRunsEmphasis', 'GLRLM_LowGreyLevelRunEmphasis', 'GLRLM_HighGreyLevelRunEmphasis', 'GLRLM_ShortRunLowGreyLevelEmphasis', 'GLRLM_ShortRunHighGreyLevelEmphasis', 'GLRLM_LongRunLowGreyLevelEmphasis', 'GLRLM_LongRunHighGreyLevelEmphasis', 'GLRLM_GreyLevelNonUniformity', 'GLRLM_RunLengthNonUniformity', 'GLRLM_RunPercentage', 'NGTDM_Coarseness', 'NGTDM_Contrast', 'NGTDM_Busyness', 'NGTDM_Complexity', 'NGTDM_Strength', 'GLSZM_SmallZoneEmphasis', 'GLSZM_LargeZoneEmphasis', 'GLSZM_LowGrayLevelZoneEmphasis', 'GLSZM_HighGrayLevelZoneEmphasis', 'GLSZM_SmallZoneLowGreyLevelEmphasis', 'GLSZM_SmallZoneHighGreyLevelEmphasis', 'GLSZM_LargeZoneLowGreyLevelEmphasis', 'GLSZM_LargeZoneHighGreyLevelEmphasis', 'GLSZM_GreyLevelNonUniformity', 'GLSZM_NormalisedGreyLevelNonUniformity', 'GLSZM_ZoneSizeNonUniformity', 'GLSZM_NormalisedZoneSizeNonUniformity', 'GLSZM_ZonePercentage', 'GLSZM_GreyLevelVariance', 'GLSZM_ZoneSizeVariance', 'GLSZM_ZoneSizeEntropy', 'subject_nodule', 'subject_id', 'nodule']\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('~/Documents/lung-treatment-response/data/merged_data.csv')\n",
    "\n",
    "# Print the shape of the dataset\n",
    "print('The shape of the dataset is:', dataset.shape)\n",
    "\n",
    "# Print the columns of the dataset\n",
    "print('The columns of the dataset are:\\n', list(dataset.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participants statistics\n",
    "\n",
    "In this first part we detail the statistics of the dataset regarding specific to the participant. \n",
    "\n",
    "To do so, we average the different features across nodules (if a participant has multiple nodule). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the dates which are not useful for the analysis\n",
    "data = dataset.drop(columns=[ 'DDD', 'Date_R_PTV', 'Date_R_homo', 'Date_R_med', 'Date_R_contro',\n",
    "                            'Date_R_horspoum','subject_nodule', 'nodule'])\n",
    "\n",
    "# We average the columns for the same patients across the different nodules\n",
    "data_grouped = data.groupby('subject_id').mean().reset_index()\n",
    "\n",
    "# We correct some values which wouldn't make sense if they have been averaged (such as yes and no categories)\n",
    "data_grouped['rechute_homo'] = data_grouped['rechute_homo'].apply(lambda x: 1 if x > 0 else 0)\n",
    "data_grouped['rechute_med'] = data_grouped['rechute_med'].apply(lambda x: 1 if x > 0 else 0)\n",
    "data_grouped['rechute_contro'] = data_grouped['rechute_contro'].apply(lambda x: 1 if x > 0 else 0)\n",
    "data_grouped['rechute_horspoum'] = data_grouped['rechute_horspoum'].apply(lambda x: 1 if x > 0 else 0)\n",
    "data_grouped['rechute_PTV'] = data_grouped['rechute_PTV'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# Replace nan values in 'DC' by 0\n",
    "data_grouped['DC'] = data_grouped['DC'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform data analysis for each of the following features: \n",
    "- `sexe`: sex of the participant (1=female, 0=male)\n",
    "- `age`: age of the participant\n",
    "- `BMI`: Body Mass Index of the participant\n",
    "- `score_charlson`: The Charlson score of the participant\n",
    "- `OMS`: \n",
    "- `tabac`: if the participant smokes (1=yes, 0=no)\n",
    "- `tabac_PA`: pack years (the number of packs smoked per year multiplied by the number of years smoked)\n",
    "- `tabac_sevre`: if the participant is weaned off tobacco\n",
    "- `DC`: if the participant died (1=yes, 0=no)\n",
    "- `cause_DC`: the cause of death (1=SPE, 2=infection, 3=AEG, 4=progression, 5=other)\n",
    "- `Reponse`: how the participant reacted to the treatment (1=stable, 0= no response)\n",
    "- `rechute_PTV`: if the participant had a local relapse (1=yes, 0=no)\n",
    "- `rechute_homo`: if the participant had a homo-lateral relapse (1=yes, 0=no)\n",
    "- `rechute_med`: if the participant had a mediastinal relapse (1=yes, 0=no)\n",
    "- `rechute_contro`: if the participant had a controlateral relapse (1=yes, 0=no)\n",
    "- `rechute_horspoum`: if the participant had a relapse outside of the lungs (1=yes, 0=no)\n",
    "- `delai_fin_DC`: the interval between the end of the treatment and death (if death occurs)\n",
    "- `delai_fin_rechutePTV`: the interval between the end of the treatment and a local relapse (if it occurs)\n",
    "- `delai_fin_rechuteHomo`: the interval between the end of the treatment and an homolateral relapse (if it occurs)\n",
    "- `delai_fin_rechuteMed`: the interval between the end of the treatment and a mediastinal relapse (if it occurs)\n",
    "- `delai_fin_rechuteContro`: the interval between the end of the treatment and a controlateral relapse (if it occurs)\n",
    "- `delai_fin_rechuteHorspoum`: the interval between the end of the treatment and a relapse outside of the lungs (if it occurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+------+\n",
      "|   Sex   | Count |  %   |\n",
      "+---------+-------+------+\n",
      "|  Female |   63  | 38.7 |\n",
      "|   Male  |  100  | 61.3 |\n",
      "| Total,  |  163  | 100  |\n",
      "+---------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# First let's look into sex\n",
    "total_participant = data_grouped.shape[0]\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Sex', 'Count', '%']\n",
    "table.add_row(['Female', data_grouped[data_grouped[\"sexe\"]==1][\"sexe\"].count(), round(data_grouped[data_grouped[\"sexe\"]==1][\"sexe\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Male', data_grouped[data_grouped[\"sexe\"]==0][\"sexe\"].count(), round(data_grouped[data_grouped[\"sexe\"]==0][\"sexe\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Total, ', total_participant, '100'])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|  Age   |      |\n",
      "+--------+------+\n",
      "|  Mean  | 71.6 |\n",
      "|  Min   | 46.0 |\n",
      "|  Max   | 93.0 |\n",
      "| Median | 71.0 |\n",
      "|  Std   | 9.7  |\n",
      "+--------+------+\n",
      "+------------+-------+------+\n",
      "|    Age     | Count |  %   |\n",
      "+------------+-------+------+\n",
      "|    <=50    |   3   | 1.8  |\n",
      "| 50<...<=60 |   16  | 9.8  |\n",
      "| 60<...<=70 |   58  | 35.6 |\n",
      "| 70<...<=80 |   56  | 34.4 |\n",
      "|    >80     |   30  | 18.4 |\n",
      "|  Missing   |   0   | 0.0  |\n",
      "+------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now let's look into age\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Age', '']\n",
    "table.add_row(['Mean', round(data_grouped[\"age\"].mean(),1)])\n",
    "table.add_row(['Min', data_grouped[\"age\"].min()])\n",
    "table.add_row(['Max', data_grouped[\"age\"].max()])\n",
    "table.add_row(['Median', data_grouped[\"age\"].median()])\n",
    "table.add_row(['Std', round(data_grouped[\"age\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Age', 'Count', '%']\n",
    "table.add_row(['<=50', data_grouped[data_grouped[\"age\"]<=50][\"age\"].count(), round(data_grouped[data_grouped[\"age\"]<=50][\"age\"].count()/total_participant*100,1)])\n",
    "table.add_row(['50<...<=60', data_grouped[(data_grouped[\"age\"]>50) & (data_grouped[\"age\"]<=60)][\"age\"].count(), round(data_grouped[(data_grouped[\"age\"]>50) & (data_grouped[\"age\"]<=60)][\"age\"].count()/total_participant*100,1)])\n",
    "table.add_row(['60<...<=70', data_grouped[(data_grouped[\"age\"]>60) & (data_grouped[\"age\"]<=70)][\"age\"].count(), round(data_grouped[(data_grouped[\"age\"]>60) & (data_grouped[\"age\"]<=70)][\"age\"].count()/total_participant*100,1)])\n",
    "table.add_row(['70<...<=80', data_grouped[(data_grouped[\"age\"]>70) & (data_grouped[\"age\"]<=80)][\"age\"].count(), round(data_grouped[(data_grouped[\"age\"]>70) & (data_grouped[\"age\"]<=80)][\"age\"].count()/total_participant*100,1)])\n",
    "table.add_row(['>80', data_grouped[data_grouped[\"age\"]>80][\"age\"].count(), round(data_grouped[data_grouped[\"age\"]>80][\"age\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped[data_grouped[\"age\"].isnull()][\"age\"].count(), round(data_grouped[data_grouped[\"age\"].isnull()][\"age\"].count()/total_participant*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|  BMI   |      |\n",
      "+--------+------+\n",
      "|  Mean  | 25.4 |\n",
      "|  Min   | 15.6 |\n",
      "|  Max   | 41.9 |\n",
      "| Median | 24.2 |\n",
      "|  Std   | 6.0  |\n",
      "+--------+------+\n",
      "+--------------+-------+------+\n",
      "|     BMI      | Count |  %   |\n",
      "+--------------+-------+------+\n",
      "|    <=18.5    |   3   | 1.8  |\n",
      "| 18.5<...<=25 |   29  | 17.8 |\n",
      "|  25<...<=30  |   14  | 8.6  |\n",
      "|  30<...<=35  |   4   | 2.5  |\n",
      "|     >35      |   5   | 3.1  |\n",
      "|   Missing    |  108  | 66.3 |\n",
      "+--------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now let's focus on the BMI\n",
    "table = PrettyTable()\n",
    "table.field_names = ['BMI', '']\n",
    "table.add_row(['Mean', round(data_grouped[\"BMI\"].mean(),1)])\n",
    "table.add_row(['Min', data_grouped[\"BMI\"].min()])\n",
    "table.add_row(['Max', data_grouped[\"BMI\"].max()])\n",
    "table.add_row(['Median', data_grouped[\"BMI\"].median()])\n",
    "table.add_row(['Std', round(data_grouped[\"BMI\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['BMI', 'Count', '%']\n",
    "table.add_row(['<=18.5', data_grouped[data_grouped[\"BMI\"]<=18.5][\"BMI\"].count(), round(data_grouped[data_grouped[\"BMI\"]<=18.5][\"BMI\"].count()/total_participant*100,1)])\n",
    "table.add_row(['18.5<...<=25', data_grouped[(data_grouped[\"BMI\"]>18.5) & (data_grouped[\"BMI\"]<=25)][\"BMI\"].count(), round(data_grouped[(data_grouped[\"BMI\"]>18.5) & (data_grouped[\"BMI\"]<=25)][\"BMI\"].count()/total_participant*100,1)])\n",
    "table.add_row(['25<...<=30', data_grouped[(data_grouped[\"BMI\"]>25) & (data_grouped[\"BMI\"]<=30)][\"BMI\"].count(), round(data_grouped[(data_grouped[\"BMI\"]>25) & (data_grouped[\"BMI\"]<=30)][\"BMI\"].count()/total_participant*100,1)])\n",
    "table.add_row(['30<...<=35', data_grouped[(data_grouped[\"BMI\"]>30) & (data_grouped[\"BMI\"]<=35)][\"BMI\"].count(), round(data_grouped[(data_grouped[\"BMI\"]>30) & (data_grouped[\"BMI\"]<=35)][\"BMI\"].count()/total_participant*100,1)])\n",
    "table.add_row(['>35', data_grouped[data_grouped[\"BMI\"]>35][\"BMI\"].count(), round(data_grouped[data_grouped[\"BMI\"]>35][\"BMI\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['BMI'].isnull().sum(), round(data_grouped['BMI'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "| Charlson score |      |\n",
      "+----------------+------+\n",
      "|      Mean      | 7.2  |\n",
      "|      Min       | 2.0  |\n",
      "|      Max       | 13.0 |\n",
      "|     Median     | 7.0  |\n",
      "|      Std       | 2.3  |\n",
      "+----------------+------+\n",
      "+----------------+-------+------+\n",
      "| Charlson score | Count |  %   |\n",
      "+----------------+-------+------+\n",
      "|      <=3       |   4   | 2.5  |\n",
      "|    3<...<=6    |   69  | 42.3 |\n",
      "|    6<...<=9    |   58  | 35.6 |\n",
      "|       >9       |   32  | 19.6 |\n",
      "|    Missing     |   0   | 0.0  |\n",
      "+----------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now let's focus on the Charlson score\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Charlson score', '']\n",
    "table.add_row(['Mean', round(data_grouped[\"score_charlson\"].mean(),1)])\n",
    "table.add_row(['Min', data_grouped[\"score_charlson\"].min()])\n",
    "table.add_row(['Max', data_grouped[\"score_charlson\"].max()])\n",
    "table.add_row(['Median', data_grouped[\"score_charlson\"].median()])\n",
    "table.add_row(['Std', round(data_grouped[\"score_charlson\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Charlson score', 'Count', '%']\n",
    "table.add_row(['<=3', data_grouped[data_grouped[\"score_charlson\"]<=3][\"score_charlson\"].count(), round(data_grouped[data_grouped[\"score_charlson\"]<=3][\"score_charlson\"].count()/total_participant*100,1)])\n",
    "table.add_row(['3<...<=6', data_grouped[(data_grouped[\"score_charlson\"]>3) & (data_grouped[\"score_charlson\"]<=6)][\"score_charlson\"].count(), round(data_grouped[(data_grouped[\"score_charlson\"]>3) & (data_grouped[\"score_charlson\"]<=6)][\"score_charlson\"].count()/total_participant*100,1)])\n",
    "table.add_row(['6<...<=9', data_grouped[(data_grouped[\"score_charlson\"]>6) & (data_grouped[\"score_charlson\"]<=9)][\"score_charlson\"].count(), round(data_grouped[(data_grouped[\"score_charlson\"]>6) & (data_grouped[\"score_charlson\"]<=9)][\"score_charlson\"].count()/total_participant*100,1)])\n",
    "table.add_row(['>9', data_grouped[data_grouped[\"score_charlson\"]>9][\"score_charlson\"].count(), round(data_grouped[data_grouped[\"score_charlson\"]>9][\"score_charlson\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['score_charlson'].isnull().sum(), round(data_grouped['score_charlson'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|  OMS   |     |\n",
      "+--------+-----+\n",
      "|  Mean  | 0.8 |\n",
      "|  Min   | 0.0 |\n",
      "|  Max   | 2.0 |\n",
      "| Median | 1.0 |\n",
      "|  Std   | 0.5 |\n",
      "+--------+-----+\n",
      "+---------+-------+------+\n",
      "|   OMS   | Count |  %   |\n",
      "+---------+-------+------+\n",
      "|    0    |   38  | 23.3 |\n",
      "|    1    |  106  | 65.0 |\n",
      "|    2    |   11  | 6.7  |\n",
      "|    3    |   0   | 0.0  |\n",
      "|    4    |   0   | 0.0  |\n",
      "| Missing |   8   | 4.9  |\n",
      "+---------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now the OMS\n",
    "table = PrettyTable()\n",
    "table.field_names = ['OMS', '']\n",
    "table.add_row(['Mean', round(data_grouped[\"OMS\"].mean(),1)])\n",
    "table.add_row(['Min', data_grouped[\"OMS\"].min()])\n",
    "table.add_row(['Max', data_grouped[\"OMS\"].max()])\n",
    "table.add_row(['Median', data_grouped[\"OMS\"].median()])\n",
    "table.add_row(['Std', round(data_grouped[\"OMS\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['OMS', 'Count', '%']\n",
    "table.add_row(['0', data_grouped[data_grouped[\"OMS\"]==0][\"OMS\"].count(), round(data_grouped[data_grouped[\"OMS\"]==0][\"OMS\"].count()/total_participant*100,1)])\n",
    "table.add_row(['1', data_grouped[data_grouped[\"OMS\"]==1][\"OMS\"].count(), round(data_grouped[data_grouped[\"OMS\"]==1][\"OMS\"].count()/total_participant*100,1)])\n",
    "table.add_row(['2', data_grouped[data_grouped[\"OMS\"]==2][\"OMS\"].count(), round(data_grouped[data_grouped[\"OMS\"]==2][\"OMS\"].count()/total_participant*100,1)])\n",
    "table.add_row(['3', data_grouped[data_grouped[\"OMS\"]==3][\"OMS\"].count(), round(data_grouped[data_grouped[\"OMS\"]==3][\"OMS\"].count()/total_participant*100,1)])\n",
    "table.add_row(['4', data_grouped[data_grouped[\"OMS\"]==4][\"OMS\"].count(), round(data_grouped[data_grouped[\"OMS\"]==4][\"OMS\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['OMS'].isnull().sum(), round(data_grouped['OMS'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------+\n",
      "| Smoking status | Count |  %   |\n",
      "+----------------+-------+------+\n",
      "|      Yes       |  123  | 75.5 |\n",
      "|       No       |   27  | 16.6 |\n",
      "|    Missing     |   13  | 8.0  |\n",
      "+----------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now the smoking status\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Smoking status', 'Count', '%']\n",
    "table.add_row(['Yes', data_grouped[data_grouped[\"tabac\"]==1][\"tabac\"].count(), round(data_grouped[data_grouped[\"tabac\"]==1][\"tabac\"].count()/total_participant*100,1)])\n",
    "table.add_row(['No', data_grouped[data_grouped[\"tabac\"]==0][\"tabac\"].count(), round(data_grouped[data_grouped[\"tabac\"]==0][\"tabac\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['tabac'].isnull().sum(), round(data_grouped['tabac'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "| Pack-years |       |\n",
      "+------------+-------+\n",
      "|    Mean    |  48.8 |\n",
      "|    Min     |  7.0  |\n",
      "|    Max     | 120.0 |\n",
      "|   Median   |  45.0 |\n",
      "|    Std     |  24.3 |\n",
      "+------------+-------+\n",
      "+------------+-------+------+\n",
      "| Pack-years | Count |  %   |\n",
      "+------------+-------+------+\n",
      "|    <=20    |   11  | 6.7  |\n",
      "| 20<...<=40 |   39  | 23.9 |\n",
      "| 40<...<=60 |   36  | 22.1 |\n",
      "|    >60     |   23  | 14.1 |\n",
      "|  Missing   |   54  | 33.1 |\n",
      "+------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now the pack-years\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Pack-years', '']\n",
    "table.add_row(['Mean', round(data_grouped[\"tabac_PA\"].mean(),1)])\n",
    "table.add_row(['Min', data_grouped[\"tabac_PA\"].min()])\n",
    "table.add_row(['Max', data_grouped[\"tabac_PA\"].max()])\n",
    "table.add_row(['Median', data_grouped[\"tabac_PA\"].median()])\n",
    "table.add_row(['Std', round(data_grouped[\"tabac_PA\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Pack-years', 'Count', '%']\n",
    "table.add_row(['<=20', data_grouped[data_grouped[\"tabac_PA\"]<=20][\"tabac_PA\"].count(), round(data_grouped[data_grouped[\"tabac_PA\"]<=20][\"tabac_PA\"].count()/total_participant*100,1)])\n",
    "table.add_row(['20<...<=40', data_grouped[(data_grouped[\"tabac_PA\"]>20) & (data_grouped[\"tabac_PA\"]<=40)][\"tabac_PA\"].count(), round(data_grouped[(data_grouped[\"tabac_PA\"]>20) & (data_grouped[\"tabac_PA\"]<=40)][\"tabac_PA\"].count()/total_participant*100,1)])\n",
    "table.add_row(['40<...<=60', data_grouped[(data_grouped[\"tabac_PA\"]>40) & (data_grouped[\"tabac_PA\"]<=60)][\"tabac_PA\"].count(), round(data_grouped[(data_grouped[\"tabac_PA\"]>40) & (data_grouped[\"tabac_PA\"]<=60)][\"tabac_PA\"].count()/total_participant*100,1)])\n",
    "table.add_row(['>60', data_grouped[data_grouped[\"tabac_PA\"]>60][\"tabac_PA\"].count(), round(data_grouped[data_grouped[\"tabac_PA\"]>60][\"tabac_PA\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['tabac_PA'].isnull().sum(), round(data_grouped['tabac_PA'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+------+\n",
      "| Weaned off smoking | Count |  %   |\n",
      "+--------------------+-------+------+\n",
      "|        Yes         |   80  | 49.1 |\n",
      "|         No         |   37  | 22.7 |\n",
      "|      Missing       |   46  | 28.2 |\n",
      "+--------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now if the participant had weaned off smoking\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Weaned off smoking', 'Count', '%']\n",
    "table.add_row(['Yes', data_grouped[data_grouped[\"tabac_sevre\"]==1][\"tabac_sevre\"].count(), round(data_grouped[data_grouped[\"tabac_sevre\"]==1][\"tabac_sevre\"].count()/total_participant*100,1)])\n",
    "table.add_row(['No', data_grouped[data_grouped[\"tabac_sevre\"]==0][\"tabac_sevre\"].count(), round(data_grouped[data_grouped[\"tabac_sevre\"]==0][\"tabac_sevre\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['tabac_sevre'].isnull().sum(), round(data_grouped['tabac_sevre'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "| Death | Count |  %   |\n",
      "+-------+-------+------+\n",
      "|  Yes  |   47  | 28.8 |\n",
      "|   No  |  116  | 71.2 |\n",
      "+-------+-------+------+\n",
      "+----------------------------------------------------+--------+\n",
      "| Interval between end of treatment and death (days) |        |\n",
      "+----------------------------------------------------+--------+\n",
      "|                        Mean                        | 801.5  |\n",
      "|                        Min                         |  0.0   |\n",
      "|                        Max                         | 2033.0 |\n",
      "|                       Median                       | 739.0  |\n",
      "|                        Std                         | 474.8  |\n",
      "+----------------------------------------------------+--------+\n",
      "+----------------------------------------------------+-------+------+\n",
      "| Interval between end of treatment and death (days) | Count |  %   |\n",
      "+----------------------------------------------------+-------+------+\n",
      "|                       <=365                        |   10  | 6.1  |\n",
      "|                    365<...<=730                    |   12  | 7.4  |\n",
      "|                   730<...<=1095                    |   11  | 6.7  |\n",
      "|                       >1095                        |   14  | 8.6  |\n",
      "|                      Missing                       |  116  | 71.2 |\n",
      "+----------------------------------------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now if the person has died or not\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Death', 'Count', '%']\n",
    "table.add_row(['Yes', data_grouped[data_grouped[\"DC\"]==1][\"DC\"].count(), round(data_grouped[data_grouped[\"DC\"]==1][\"DC\"].count()/total_participant*100,1)])\n",
    "table.add_row(['No', data_grouped[data_grouped[\"DC\"]==0][\"DC\"].count(), round(data_grouped[data_grouped[\"DC\"]==0][\"DC\"].count()/total_participant*100,1)])\n",
    "print(table)\n",
    "# And the interval between the end of treatment and death\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Interval between end of treatment and death (days)', '']\n",
    "table.add_row(['Mean', round(data_grouped[\"delai_fin_DC\"].mean(),1)])\n",
    "table.add_row(['Min', data_grouped[\"delai_fin_DC\"].min()])\n",
    "table.add_row(['Max', data_grouped[\"delai_fin_DC\"].max()])\n",
    "table.add_row(['Median', data_grouped[\"delai_fin_DC\"].median()])\n",
    "table.add_row(['Std', round(data_grouped[\"delai_fin_DC\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Interval between end of treatment and death (days)', 'Count', '%']\n",
    "table.add_row(['<=365', data_grouped[data_grouped[\"delai_fin_DC\"]<=365][\"delai_fin_DC\"].count(), round(data_grouped[data_grouped[\"delai_fin_DC\"]<=365][\"delai_fin_DC\"].count()/total_participant*100,1)])\n",
    "table.add_row(['365<...<=730', data_grouped[(data_grouped[\"delai_fin_DC\"]>365) & (data_grouped[\"delai_fin_DC\"]<=730)][\"delai_fin_DC\"].count(), round(data_grouped[(data_grouped[\"delai_fin_DC\"]>365) & (data_grouped[\"delai_fin_DC\"]<=730)][\"delai_fin_DC\"].count()/total_participant*100,1)])\n",
    "table.add_row(['730<...<=1095', data_grouped[(data_grouped[\"delai_fin_DC\"]>730) & (data_grouped[\"delai_fin_DC\"]<=1095)][\"delai_fin_DC\"].count(), round(data_grouped[(data_grouped[\"delai_fin_DC\"]>730) & (data_grouped[\"delai_fin_DC\"]<=1095)][\"delai_fin_DC\"].count()/total_participant*100,1)])\n",
    "table.add_row(['>1095', data_grouped[data_grouped[\"delai_fin_DC\"]>1095][\"delai_fin_DC\"].count(), round(data_grouped[data_grouped[\"delai_fin_DC\"]>1095][\"delai_fin_DC\"].count()/total_participant*100,1)])  \n",
    "table.add_row(['Missing', data_grouped['delai_fin_DC'].isnull().sum(), round(data_grouped['delai_fin_DC'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------------+\n",
      "| Cause of death | Count | % of total death |\n",
      "+----------------+-------+------------------+\n",
      "|      SPE       |   7   |       14.9       |\n",
      "|   Infection    |   4   |       8.5        |\n",
      "|      AEG       |   2   |       4.3        |\n",
      "|  Progression   |   3   |       6.4        |\n",
      "|     Other      |   2   |       4.3        |\n",
      "|    Missing     |   29  |       61.7       |\n",
      "+----------------+-------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Now we look at the cause of death\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Cause of death', 'Count', '% of total death']\n",
    "table.add_row(['SPE', data_grouped[data_grouped[\"cause_DC\"]==1][\"cause_DC\"].count(), round(data_grouped[data_grouped[\"cause_DC\"]==1][\"cause_DC\"].count()/data_grouped[data_grouped[\"DC\"]==1][\"DC\"].count()*100,1)])\n",
    "table.add_row(['Infection', data_grouped[data_grouped[\"cause_DC\"]==2][\"cause_DC\"].count(), round(data_grouped[data_grouped[\"cause_DC\"]==2][\"cause_DC\"].count()/data_grouped[data_grouped[\"DC\"]==1][\"DC\"].count()*100,1)])\n",
    "table.add_row(['AEG', data_grouped[data_grouped[\"cause_DC\"]==3][\"cause_DC\"].count(), round(data_grouped[data_grouped[\"cause_DC\"]==3][\"cause_DC\"].count()/data_grouped[data_grouped[\"DC\"]==1][\"DC\"].count()*100,1)])\n",
    "table.add_row(['Progression', data_grouped[data_grouped[\"cause_DC\"]==4][\"cause_DC\"].count(), round(data_grouped[data_grouped[\"cause_DC\"]==4][\"cause_DC\"].count()/data_grouped[data_grouped[\"DC\"]==1][\"DC\"].count()*100,1)])\n",
    "table.add_row(['Other', data_grouped[data_grouped[\"cause_DC\"]==5][\"cause_DC\"].count(), round(data_grouped[data_grouped[\"cause_DC\"]==5][\"cause_DC\"].count()/data_grouped[data_grouped[\"DC\"]==1][\"DC\"].count()*100,1)])\n",
    "table.add_row(['Missing', data_grouped['cause_DC'].isnull().sum()-data_grouped[data_grouped[\"DC\"]==0][\"DC\"].count(), round((data_grouped['cause_DC'].isnull().sum()-data_grouped[data_grouped[\"DC\"]==0][\"DC\"].count())/data_grouped[data_grouped[\"DC\"]==1][\"DC\"].count()*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------+------+\n",
      "| Response to treatment | Count |  %   |\n",
      "+-----------------------+-------+------+\n",
      "|         Stable        |  112  | 68.7 |\n",
      "|      No response      |   3   | 1.8  |\n",
      "|        Missing        |   48  | 29.4 |\n",
      "+-----------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now we look at the response to the treatment\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Response to treatment', 'Count', '%']\n",
    "table.add_row(['Stable', data_grouped[data_grouped['Reponse']==1][\"Reponse\"].count(), round(data_grouped[data_grouped['Reponse']==1][\"Reponse\"].count()/total_participant*100,1)])\n",
    "table.add_row(['No response', data_grouped[data_grouped['Reponse']==0][\"Reponse\"].count(), round(data_grouped[data_grouped['Reponse']==0][\"Reponse\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['Reponse'].isnull().sum(), round(data_grouped['Reponse'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+------+\n",
      "| Local relapse | Count |  %   |\n",
      "+---------------+-------+------+\n",
      "|      Yes      |   24  | 14.7 |\n",
      "|       No      |  139  | 85.3 |\n",
      "|    Missing    |   0   | 0.0  |\n",
      "+---------------+-------+------+\n",
      "+-------------------------------+--------+\n",
      "| Local relapse interval (days) |        |\n",
      "+-------------------------------+--------+\n",
      "|              Mean             | 451.5  |\n",
      "|              Min              |  0.0   |\n",
      "|              Max              | 1175.0 |\n",
      "|             Median            | 405.5  |\n",
      "|              Std              | 292.2  |\n",
      "+-------------------------------+--------+\n",
      "+-------------------------------+-------+------+\n",
      "| Local relapse interval (days) | Count |  %   |\n",
      "+-------------------------------+-------+------+\n",
      "|             <=365             |   10  | 6.1  |\n",
      "|          365<...<=730         |   11  | 6.7  |\n",
      "|         730<...<=1095         |   1   | 0.6  |\n",
      "|             >1095             |   2   | 1.2  |\n",
      "|            Missing            |  139  | 85.3 |\n",
      "+-------------------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now we look at local relapse\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Local relapse', 'Count', '%']\n",
    "table.add_row(['Yes', data_grouped[data_grouped['rechute_PTV']==1][\"rechute_PTV\"].count(), round(data_grouped[data_grouped['rechute_PTV']==1][\"rechute_PTV\"].count()/total_participant*100,1)])\n",
    "table.add_row(['No', data_grouped[data_grouped['rechute_PTV']==0][\"rechute_PTV\"].count(), round(data_grouped[data_grouped['rechute_PTV']==0][\"rechute_PTV\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['rechute_PTV'].isnull().sum(), round(data_grouped['rechute_PTV'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)\n",
    "# And the interval between the end of the treatment and the local relapse\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Local relapse interval (days)', '']\n",
    "table.add_row(['Mean', round(data_grouped[\"delai_fin_rechutePTV\"].mean(),1)])\n",
    "table.add_row(['Min', data_grouped[\"delai_fin_rechutePTV\"].min()])\n",
    "table.add_row(['Max', data_grouped[\"delai_fin_rechutePTV\"].max()])\n",
    "table.add_row(['Median', data_grouped[\"delai_fin_rechutePTV\"].median()])\n",
    "table.add_row(['Std', round(data_grouped[\"delai_fin_rechutePTV\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Local relapse interval (days)', 'Count', '%']\n",
    "table.add_row(['<=365', data_grouped[data_grouped[\"delai_fin_rechutePTV\"]<=365][\"delai_fin_rechutePTV\"].count(), round(data_grouped[data_grouped[\"delai_fin_rechutePTV\"]<=365][\"delai_fin_rechutePTV\"].count()/total_participant*100,1)])\n",
    "table.add_row(['365<...<=730', data_grouped[(data_grouped[\"delai_fin_rechutePTV\"]>365) & (data_grouped[\"delai_fin_rechutePTV\"]<=730)][\"delai_fin_rechutePTV\"].count(), round(data_grouped[(data_grouped[\"delai_fin_rechutePTV\"]>365) & (data_grouped[\"delai_fin_rechutePTV\"]<=730)][\"delai_fin_rechutePTV\"].count()/total_participant*100,1)])\n",
    "table.add_row(['730<...<=1095', data_grouped[(data_grouped[\"delai_fin_rechutePTV\"]>730) & (data_grouped[\"delai_fin_rechutePTV\"]<=1095)][\"delai_fin_rechutePTV\"].count(), round(data_grouped[(data_grouped[\"delai_fin_rechutePTV\"]>730) & (data_grouped[\"delai_fin_rechutePTV\"]<=1095)][\"delai_fin_rechutePTV\"].count()/total_participant*100,1)])\n",
    "table.add_row(['>1095', data_grouped[data_grouped[\"delai_fin_rechutePTV\"]>1095][\"delai_fin_rechutePTV\"].count(), round(data_grouped[data_grouped[\"delai_fin_rechutePTV\"]>1095][\"delai_fin_rechutePTV\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['delai_fin_rechutePTV'].isnull().sum(), round(data_grouped['delai_fin_rechutePTV'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------+------+\n",
      "| Homolateral relapse | Count |  %   |\n",
      "+---------------------+-------+------+\n",
      "|         Yes         |   25  | 15.3 |\n",
      "|          No         |  138  | 84.7 |\n",
      "|       Missing       |   0   | 0.0  |\n",
      "+---------------------+-------+------+\n",
      "+-------------------------------------+--------+\n",
      "| Homolateral relapse interval (days) |        |\n",
      "+-------------------------------------+--------+\n",
      "|                 Mean                | 516.8  |\n",
      "|                 Min                 |  64.0  |\n",
      "|                 Max                 | 1077.0 |\n",
      "|                Median               | 503.0  |\n",
      "|                 Std                 | 308.4  |\n",
      "+-------------------------------------+--------+\n",
      "+-------------------------------------+-------+------+\n",
      "| Homolateral relapse interval (days) | Count |  %   |\n",
      "+-------------------------------------+-------+------+\n",
      "|                <=365                |   9   | 5.5  |\n",
      "|             365<...<=730            |   9   | 5.5  |\n",
      "|            730<...<=1095            |   7   | 4.3  |\n",
      "|                >1095                |   0   | 0.0  |\n",
      "|               Missing               |  138  | 84.7 |\n",
      "+-------------------------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now we look at relapse in the homolateral lung\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Homolateral relapse', 'Count', '%']\n",
    "table.add_row(['Yes', data_grouped[data_grouped['rechute_homo']==1][\"rechute_homo\"].count(), round(data_grouped[data_grouped['rechute_homo']==1][\"rechute_homo\"].count()/total_participant*100,1)])\n",
    "table.add_row(['No', data_grouped[data_grouped['rechute_homo']==0][\"rechute_homo\"].count(), round(data_grouped[data_grouped['rechute_homo']==0][\"rechute_homo\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['rechute_homo'].isnull().sum(), round(data_grouped['rechute_homo'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)\n",
    "# And the interval between the end of the treatment and the homolateral relapse\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Homolateral relapse interval (days)', '']\n",
    "table.add_row(['Mean', round(data_grouped[\"delai_fin_rechuteHomo\"].mean(),1)])\n",
    "table.add_row(['Min', data_grouped[\"delai_fin_rechuteHomo\"].min()])\n",
    "table.add_row(['Max', data_grouped[\"delai_fin_rechuteHomo\"].max()])\n",
    "table.add_row(['Median', data_grouped[\"delai_fin_rechuteHomo\"].median()])\n",
    "table.add_row(['Std', round(data_grouped[\"delai_fin_rechuteHomo\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Homolateral relapse interval (days)', 'Count', '%']\n",
    "table.add_row(['<=365', data_grouped[data_grouped[\"delai_fin_rechuteHomo\"]<=365][\"delai_fin_rechuteHomo\"].count(), round(data_grouped[data_grouped[\"delai_fin_rechuteHomo\"]<=365][\"delai_fin_rechuteHomo\"].count()/total_participant*100,1)])\n",
    "table.add_row(['365<...<=730', data_grouped[(data_grouped[\"delai_fin_rechuteHomo\"]>365) & (data_grouped[\"delai_fin_rechuteHomo\"]<=730)][\"delai_fin_rechuteHomo\"].count(), round(data_grouped[(data_grouped[\"delai_fin_rechuteHomo\"]>365) & (data_grouped[\"delai_fin_rechuteHomo\"]<=730)][\"delai_fin_rechuteHomo\"].count()/total_participant*100,1)])\n",
    "table.add_row(['730<...<=1095', data_grouped[(data_grouped[\"delai_fin_rechuteHomo\"]>730) & (data_grouped[\"delai_fin_rechuteHomo\"]<=1095)][\"delai_fin_rechuteHomo\"].count(), round(data_grouped[(data_grouped[\"delai_fin_rechuteHomo\"]>730) & (data_grouped[\"delai_fin_rechuteHomo\"]<=1095)][\"delai_fin_rechuteHomo\"].count()/total_participant*100,1)])\n",
    "table.add_row(['>1095', data_grouped[data_grouped[\"delai_fin_rechuteHomo\"]>1095][\"delai_fin_rechuteHomo\"].count(), round(data_grouped[data_grouped[\"delai_fin_rechuteHomo\"]>1095][\"delai_fin_rechuteHomo\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['delai_fin_rechuteHomo'].isnull().sum(), round(data_grouped['delai_fin_rechuteHomo'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------+------+\n",
      "| Mediastinal relapse | Count |  %   |\n",
      "+---------------------+-------+------+\n",
      "|         Yes         |   19  | 11.7 |\n",
      "|          No         |  144  | 88.3 |\n",
      "|       Missing       |   0   | 0.0  |\n",
      "+---------------------+-------+------+\n",
      "+-------------------------------------+--------+\n",
      "| Mediastinal relapse interval (days) |        |\n",
      "+-------------------------------------+--------+\n",
      "|                 Mean                | 419.4  |\n",
      "|                 Min                 |  59.0  |\n",
      "|                 Max                 | 1413.0 |\n",
      "|                Median               | 413.0  |\n",
      "|                 Std                 | 327.3  |\n",
      "+-------------------------------------+--------+\n",
      "+-------------------------------------+-------+------+\n",
      "| Mediastinal relapse interval (days) | Count |  %   |\n",
      "+-------------------------------------+-------+------+\n",
      "|                <=365                |   8   | 4.9  |\n",
      "|             365<...<=730            |   9   | 5.5  |\n",
      "|            730<...<=1095            |   1   | 0.6  |\n",
      "|                >1095                |   1   | 0.6  |\n",
      "|               Missing               |  144  | 88.3 |\n",
      "+-------------------------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now we look at relapse in the mediastinum\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Mediastinal relapse', 'Count', '%']\n",
    "table.add_row(['Yes', data_grouped[data_grouped['rechute_med']==1][\"rechute_med\"].count(), round(data_grouped[data_grouped['rechute_med']==1][\"rechute_med\"].count()/total_participant*100,1)])\n",
    "table.add_row(['No', data_grouped[data_grouped['rechute_med']==0][\"rechute_med\"].count(), round(data_grouped[data_grouped['rechute_med']==0][\"rechute_med\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['rechute_med'].isnull().sum(), round(data_grouped['rechute_med'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)\n",
    "# And the interval between the end of the treatment and the mediastinum relapse\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Mediastinal relapse interval (days)', '']\n",
    "table.add_row(['Mean', round(data_grouped[\"delai_fin_rechuteMed\"].mean(),1)])\n",
    "table.add_row(['Min', data_grouped[\"delai_fin_rechuteMed\"].min()])\n",
    "table.add_row(['Max', data_grouped[\"delai_fin_rechuteMed\"].max()])\n",
    "table.add_row(['Median', data_grouped[\"delai_fin_rechuteMed\"].median()])\n",
    "table.add_row(['Std', round(data_grouped[\"delai_fin_rechuteMed\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Mediastinal relapse interval (days)', 'Count', '%']\n",
    "table.add_row(['<=365', data_grouped[data_grouped[\"delai_fin_rechuteMed\"]<=365][\"delai_fin_rechuteMed\"].count(), round(data_grouped[data_grouped[\"delai_fin_rechuteMed\"]<=365][\"delai_fin_rechuteMed\"].count()/total_participant*100,1)])\n",
    "table.add_row(['365<...<=730', data_grouped[(data_grouped[\"delai_fin_rechuteMed\"]>365) & (data_grouped[\"delai_fin_rechuteMed\"]<=730)][\"delai_fin_rechuteMed\"].count(), round(data_grouped[(data_grouped[\"delai_fin_rechuteMed\"]>365) & (data_grouped[\"delai_fin_rechuteMed\"]<=730)][\"delai_fin_rechuteMed\"].count()/total_participant*100,1)])\n",
    "table.add_row(['730<...<=1095', data_grouped[(data_grouped[\"delai_fin_rechuteMed\"]>730) & (data_grouped[\"delai_fin_rechuteMed\"]<=1095)][\"delai_fin_rechuteMed\"].count(), round(data_grouped[(data_grouped[\"delai_fin_rechuteMed\"]>730) & (data_grouped[\"delai_fin_rechuteMed\"]<=1095)][\"delai_fin_rechuteMed\"].count()/total_participant*100,1)])\n",
    "table.add_row(['>1095', data_grouped[data_grouped[\"delai_fin_rechuteMed\"]>1095][\"delai_fin_rechuteMed\"].count(), round(data_grouped[data_grouped[\"delai_fin_rechuteMed\"]>1095][\"delai_fin_rechuteMed\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['delai_fin_rechuteMed'].isnull().sum(), round(data_grouped['delai_fin_rechuteMed'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------+------+\n",
      "| Contralateral relapse | Count |  %   |\n",
      "+-----------------------+-------+------+\n",
      "|          Yes          |   23  | 14.1 |\n",
      "|           No          |  140  | 85.9 |\n",
      "|        Missing        |   0   | 0.0  |\n",
      "+-----------------------+-------+------+\n",
      "+---------------------------------------+--------+\n",
      "| Contralateral relapse interval (days) |        |\n",
      "+---------------------------------------+--------+\n",
      "|                  Mean                 | 503.5  |\n",
      "|                  Min                  |  0.0   |\n",
      "|                  Max                  | 1409.0 |\n",
      "|                 Median                | 503.0  |\n",
      "|                  Std                  | 347.1  |\n",
      "+---------------------------------------+--------+\n",
      "+---------------------------------------+-------+------+\n",
      "| Contralateral relapse interval (days) | Count |  %   |\n",
      "+---------------------------------------+-------+------+\n",
      "|                 <=365                 |   8   | 4.9  |\n",
      "|              365<...<=730             |   10  | 6.1  |\n",
      "|             730<...<=1095             |   4   | 2.5  |\n",
      "|                 >1095                 |   1   | 0.6  |\n",
      "|                Missing                |  140  | 85.9 |\n",
      "+---------------------------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now we look at relapse in the contralateral lung\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Contralateral relapse', 'Count', '%']\n",
    "table.add_row(['Yes', data_grouped[data_grouped['rechute_contro']==1][\"rechute_contro\"].count(), round(data_grouped[data_grouped['rechute_contro']==1][\"rechute_contro\"].count()/total_participant*100,1)])\n",
    "table.add_row(['No', data_grouped[data_grouped['rechute_contro']==0][\"rechute_contro\"].count(), round(data_grouped[data_grouped['rechute_contro']==0][\"rechute_contro\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['rechute_contro'].isnull().sum(), round(data_grouped['rechute_contro'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)\n",
    "# And the interval between the end of the treatment and the contralateral relapse\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Contralateral relapse interval (days)', '']\n",
    "table.add_row(['Mean', round(data_grouped[\"delai_fin_rechuteContro\"].mean(),1)])\n",
    "table.add_row(['Min', data_grouped[\"delai_fin_rechuteContro\"].min()])\n",
    "table.add_row(['Max', data_grouped[\"delai_fin_rechuteContro\"].max()])\n",
    "table.add_row(['Median', data_grouped[\"delai_fin_rechuteContro\"].median()])\n",
    "table.add_row(['Std', round(data_grouped[\"delai_fin_rechuteContro\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Contralateral relapse interval (days)', 'Count', '%']\n",
    "table.add_row(['<=365', data_grouped[data_grouped[\"delai_fin_rechuteContro\"]<=365][\"delai_fin_rechuteContro\"].count(), round(data_grouped[data_grouped[\"delai_fin_rechuteContro\"]<=365][\"delai_fin_rechuteContro\"].count()/total_participant*100,1)])\n",
    "table.add_row(['365<...<=730', data_grouped[(data_grouped[\"delai_fin_rechuteContro\"]>365) & (data_grouped[\"delai_fin_rechuteContro\"]<=730)][\"delai_fin_rechuteContro\"].count(), round(data_grouped[(data_grouped[\"delai_fin_rechuteContro\"]>365) & (data_grouped[\"delai_fin_rechuteContro\"]<=730)][\"delai_fin_rechuteContro\"].count()/total_participant*100,1)])\n",
    "table.add_row(['730<...<=1095', data_grouped[(data_grouped[\"delai_fin_rechuteContro\"]>730) & (data_grouped[\"delai_fin_rechuteContro\"]<=1095)][\"delai_fin_rechuteContro\"].count(), round(data_grouped[(data_grouped[\"delai_fin_rechuteContro\"]>730) & (data_grouped[\"delai_fin_rechuteContro\"]<=1095)][\"delai_fin_rechuteContro\"].count()/total_participant*100,1)])\n",
    "table.add_row(['>1095', data_grouped[data_grouped[\"delai_fin_rechuteContro\"]>1095][\"delai_fin_rechuteContro\"].count(), round(data_grouped[data_grouped[\"delai_fin_rechuteContro\"]>1095][\"delai_fin_rechuteContro\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['delai_fin_rechuteContro'].isnull().sum(), round(data_grouped['delai_fin_rechuteContro'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------+------+\n",
      "| Outside lung relapse | Count |  %   |\n",
      "+----------------------+-------+------+\n",
      "|         Yes          |   35  | 21.5 |\n",
      "|          No          |  128  | 78.5 |\n",
      "|       Missing        |   0   | 0.0  |\n",
      "+----------------------+-------+------+\n",
      "+--------------------------------------+--------+\n",
      "| Outside lung relapse interval (days) |        |\n",
      "+--------------------------------------+--------+\n",
      "|                 Mean                 | 497.7  |\n",
      "|                 Min                  |  59.0  |\n",
      "|                 Max                  | 1413.0 |\n",
      "|                Median                | 476.5  |\n",
      "|                 Std                  | 299.7  |\n",
      "+--------------------------------------+--------+\n",
      "+--------------------------------------+-------+------+\n",
      "| Outside lung relapse interval (days) | Count |  %   |\n",
      "+--------------------------------------+-------+------+\n",
      "|                <=365                 |   14  | 8.6  |\n",
      "|             365<...<=730             |   12  | 7.4  |\n",
      "|            730<...<=1095             |   4   | 2.5  |\n",
      "|                >1095                 |   2   | 1.2  |\n",
      "|               Missing                |  131  | 80.4 |\n",
      "+--------------------------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now we look at relapse outside the lungs\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Outside lung relapse', 'Count', '%']\n",
    "table.add_row(['Yes', data_grouped[data_grouped['rechute_horspoum']==1][\"rechute_horspoum\"].count(), round(data_grouped[data_grouped['rechute_horspoum']==1][\"rechute_horspoum\"].count()/total_participant*100,1)])\n",
    "table.add_row(['No', data_grouped[data_grouped['rechute_horspoum']==0][\"rechute_horspoum\"].count(), round(data_grouped[data_grouped['rechute_horspoum']==0][\"rechute_horspoum\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['rechute_horspoum'].isnull().sum(), round(data_grouped['rechute_horspoum'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)\n",
    "# And the interval between the end of the treatment and the outside lung relapse\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Outside lung relapse interval (days)', '']\n",
    "table.add_row(['Mean', round(data_grouped[\"delai_fin_rechuteHorspoum\"].mean(),1)])\n",
    "table.add_row(['Min', data_grouped[\"delai_fin_rechuteHorspoum\"].min()])\n",
    "table.add_row(['Max', data_grouped[\"delai_fin_rechuteHorspoum\"].max()])\n",
    "table.add_row(['Median', data_grouped[\"delai_fin_rechuteHorspoum\"].median()])\n",
    "table.add_row(['Std', round(data_grouped[\"delai_fin_rechuteHorspoum\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Outside lung relapse interval (days)', 'Count', '%']\n",
    "table.add_row(['<=365', data_grouped[data_grouped[\"delai_fin_rechuteHorspoum\"]<=365][\"delai_fin_rechuteHorspoum\"].count(), round(data_grouped[data_grouped[\"delai_fin_rechuteHorspoum\"]<=365][\"delai_fin_rechuteHorspoum\"].count()/total_participant*100,1)])\n",
    "table.add_row(['365<...<=730', data_grouped[(data_grouped[\"delai_fin_rechuteHorspoum\"]>365) & (data_grouped[\"delai_fin_rechuteHorspoum\"]<=730)][\"delai_fin_rechuteHorspoum\"].count(), round(data_grouped[(data_grouped[\"delai_fin_rechuteHorspoum\"]>365) & (data_grouped[\"delai_fin_rechuteHorspoum\"]<=730)][\"delai_fin_rechuteHorspoum\"].count()/total_participant*100,1)])\n",
    "table.add_row(['730<...<=1095', data_grouped[(data_grouped[\"delai_fin_rechuteHorspoum\"]>730) & (data_grouped[\"delai_fin_rechuteHorspoum\"]<=1095)][\"delai_fin_rechuteHorspoum\"].count(), round(data_grouped[(data_grouped[\"delai_fin_rechuteHorspoum\"]>730) & (data_grouped[\"delai_fin_rechuteHorspoum\"]<=1095)][\"delai_fin_rechuteHorspoum\"].count()/total_participant*100,1)])\n",
    "table.add_row(['>1095', data_grouped[data_grouped[\"delai_fin_rechuteHorspoum\"]>1095][\"delai_fin_rechuteHorspoum\"].count(), round(data_grouped[data_grouped[\"delai_fin_rechuteHorspoum\"]>1095][\"delai_fin_rechuteHorspoum\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['delai_fin_rechuteHorspoum'].isnull().sum(), round(data_grouped['delai_fin_rechuteHorspoum'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------+\n",
      "| Follow-up time (days) |        |\n",
      "+-----------------------+--------+\n",
      "|          Mean         | 949.7  |\n",
      "|          Min          |  21.0  |\n",
      "|          Max          | 2025.0 |\n",
      "|         Median        | 782.0  |\n",
      "|          Std          | 512.8  |\n",
      "+-----------------------+--------+\n",
      "+-----------------------+-------+------+\n",
      "| Follow-up time (days) | Count |  %   |\n",
      "+-----------------------+-------+------+\n",
      "|         <=365         |   9   | 5.5  |\n",
      "|      365<...<=730     |   54  | 33.1 |\n",
      "|     730<...<=1095     |   41  | 25.2 |\n",
      "|         >1095         |   44  | 27.0 |\n",
      "|        Missing        |   15  | 9.2  |\n",
      "+-----------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now we look at the follow-up time\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Follow-up time (days)', '']\n",
    "table.add_row(['Mean', round(data_grouped[\"follow_up\"].mean(),1)])\n",
    "table.add_row(['Min', data_grouped[\"follow_up\"].min()])\n",
    "table.add_row(['Max', data_grouped[\"follow_up\"].max()])\n",
    "table.add_row(['Median', data_grouped[\"follow_up\"].median()])\n",
    "table.add_row(['Std', round(data_grouped[\"follow_up\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Follow-up time (days)', 'Count', '%']\n",
    "table.add_row(['<=365', data_grouped[data_grouped[\"follow_up\"]<=365][\"follow_up\"].count(), round(data_grouped[data_grouped[\"follow_up\"]<=365][\"follow_up\"].count()/total_participant*100,1)])\n",
    "table.add_row(['365<...<=730', data_grouped[(data_grouped[\"follow_up\"]>365) & (data_grouped[\"follow_up\"]<=730)][\"follow_up\"].count(), round(data_grouped[(data_grouped[\"follow_up\"]>365) & (data_grouped[\"follow_up\"]<=730)][\"follow_up\"].count()/total_participant*100,1)])\n",
    "table.add_row(['730<...<=1095', data_grouped[(data_grouped[\"follow_up\"]>730) & (data_grouped[\"follow_up\"]<=1095)][\"follow_up\"].count(), round(data_grouped[(data_grouped[\"follow_up\"]>730) & (data_grouped[\"follow_up\"]<=1095)][\"follow_up\"].count()/total_participant*100,1)])\n",
    "table.add_row(['>1095', data_grouped[data_grouped[\"follow_up\"]>1095][\"follow_up\"].count(), round(data_grouped[data_grouped[\"follow_up\"]>1095][\"follow_up\"].count()/total_participant*100,1)])\n",
    "table.add_row(['Missing', data_grouped['follow_up'].isnull().sum(), round(data_grouped['follow_up'].isnull().sum()/total_participant*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodule analysis\n",
    "\n",
    "In this section of the dataset analysis we focus on the analysis of the nodules. \n",
    "\n",
    "We will specifically detail the following features:\n",
    "- `histo`: the nodule histology (1=ADK, 2=CE, 3=other, 4=NC)\n",
    "- `T`: T stage of the nodule (1=T1=<3cm, 2=T2: Tumor > 3 cm but  5 cm, or involving bronchus, visceral pleura, causing atelectasis or obstructive pneumonia, 3=T3: Tumor > 5 cm but  7 cm, or involving pericardium, parietal pleura, phrenic nerve, or separate tumor nodules in the same lobe, 4=T4: Tumor > 7 cm or involving critical organs, or separate tumor nodules in different lobes, 5=Primary tumor size cannot be assessed or information is insufficient.)\n",
    "- `centrale`: whether the tumor is centrally located within the lung (1=yes=<2cm, 0=no)\n",
    "- `dose_tot`: total dose of radiation (in Gray)\n",
    "- `etalement`: the duration of the radiation therapy (in days)\n",
    "- `vol_GTV`: volume of the Gross Tumor Volume (in cm3)\n",
    "- `vol_PTV`: volume of the Planning Target Volume (in cm3)\n",
    "- `vol_ITV`: volume of the Internal Target Volume (in cm3)\n",
    "- `couv-PTV`: coverage of the Planning Target Volume (in cm3)\n",
    "- `BED_10`: Biologically Effective Dose with an / ratio of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodules: 181\n",
      "Average number of nodules per patient: 1.11\n"
     ]
    }
   ],
   "source": [
    "# We first describe the data\n",
    "## Print the number of nodules\n",
    "print(\"Number of nodules:\",data.shape[0])\n",
    "# Average number of nodule per patient\n",
    "print(\"Average number of nodules per patient:\",round(data.shape[0]/data_grouped.shape[0],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------+\n",
      "| Histology | Count | % of nodules |\n",
      "+-----------+-------+--------------+\n",
      "|    ADK    |   29  |     16.0     |\n",
      "|     CE    |   15  |     8.3      |\n",
      "|   Other   |   6   |     3.3      |\n",
      "|     NC    |  131  |     72.4     |\n",
      "|  Missing  |   0   |     0.0      |\n",
      "+-----------+-------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# We first look into histology\n",
    "total_nodules = data.shape[0]\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Histology', 'Count', '% of nodules']\n",
    "table.add_row(['ADK', data[data['histo']==1][\"histo\"].count(), round(data[data['histo']==1][\"histo\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['CE', data[data['histo']==2][\"histo\"].count(), round(data[data['histo']==2][\"histo\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['Other', data[data['histo']==3][\"histo\"].count(), round(data[data['histo']==3][\"histo\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['NC', data[data['histo']==4][\"histo\"].count(), round(data[data['histo']==4][\"histo\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['Missing', data['histo'].isnull().sum(), round(data['histo'].isnull().sum()/total_nodules*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------------+\n",
      "| T stage | Count | % of nodules |\n",
      "+---------+-------+--------------+\n",
      "|    T1   |   97  |     53.6     |\n",
      "|    T2   |   16  |     8.8      |\n",
      "|    T3   |   0   |     0.0      |\n",
      "|    T4   |   0   |     0.0      |\n",
      "|    Tx   |   1   |     0.6      |\n",
      "| Missing |   67  |     37.0     |\n",
      "+---------+-------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# We now look at T\n",
    "table = PrettyTable()\n",
    "table.field_names = ['T stage', 'Count', '% of nodules']\n",
    "table.add_row(['T1', data[data['T']==1][\"T\"].count(), round(data[data['T']==1][\"T\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['T2', data[data['T']==2][\"T\"].count(), round(data[data['T']==2][\"T\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['T3', data[data['T']==3][\"T\"].count(), round(data[data['T']==3][\"T\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['T4', data[data['T']==4][\"T\"].count(), round(data[data['T']==4][\"T\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['Tx', data[data['T']==5][\"T\"].count(), round(data[data['T']==5][\"T\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['Missing', data['T'].isnull().sum(), round(data['T'].isnull().sum()/total_nodules*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+--------------+\n",
      "|  Central   | Count | % of nodules |\n",
      "+------------+-------+--------------+\n",
      "| Yes, <=2cm |   48  |     26.5     |\n",
      "|     No     |  133  |     73.5     |\n",
      "|  Missing   |   0   |     0.0      |\n",
      "+------------+-------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# Now we look at 'centrale' \n",
    "table = PrettyTable()\n",
    "table.field_names = ['Central', 'Count', '% of nodules']\n",
    "table.add_row(['Yes, <=2cm', data[data['centrale']==1][\"centrale\"].count(), round(data[data['centrale']==1][\"centrale\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['No', data[data['centrale']==0][\"centrale\"].count(), round(data[data['centrale']==0][\"centrale\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['Missing', data['centrale'].isnull().sum(), round(data['centrale'].isnull().sum()/total_nodules*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------+\n",
      "| Total dose (in Gray) |      |\n",
      "+----------------------+------+\n",
      "|         Mean         | 56.2 |\n",
      "|         Min          | 30.0 |\n",
      "|         Max          | 60.0 |\n",
      "|        Median        | 60.0 |\n",
      "|         Std          | 5.8  |\n",
      "+----------------------+------+\n",
      "+----------------------+-------+------+\n",
      "| Total dose (in Gray) | Count |  %   |\n",
      "+----------------------+-------+------+\n",
      "|         <=50         |   32  | 17.7 |\n",
      "|      50<...<=55      |   41  | 22.7 |\n",
      "|         >55          |  108  | 59.7 |\n",
      "|       Missing        |   0   | 0.0  |\n",
      "+----------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now we look at the total dose (in Gray)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Total dose (in Gray)', '']\n",
    "table.add_row(['Mean', round(data[\"dose_tot\"].mean(),1)])\n",
    "table.add_row(['Min', data[\"dose_tot\"].min()])\n",
    "table.add_row(['Max', data[\"dose_tot\"].max()])\n",
    "table.add_row(['Median', data[\"dose_tot\"].median()])\n",
    "table.add_row(['Std', round(data[\"dose_tot\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Total dose (in Gray)', 'Count', '%']\n",
    "table.add_row(['<=50', data[data[\"dose_tot\"]<=50][\"dose_tot\"].count(), round(data[data[\"dose_tot\"]<=50][\"dose_tot\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['50<...<=55', data[(data[\"dose_tot\"]>50) & (data[\"dose_tot\"]<=55)][\"dose_tot\"].count(), round(data[(data[\"dose_tot\"]>50) & (data[\"dose_tot\"]<=55)][\"dose_tot\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['>55', data[data[\"dose_tot\"]>55][\"dose_tot\"].count(), round(data[data[\"dose_tot\"]>55][\"dose_tot\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['Missing', data['dose_tot'].isnull().sum(), round(data['dose_tot'].isnull().sum()/total_nodules*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------+\n",
      "| Treatment duration (in days) |      |\n",
      "+------------------------------+------+\n",
      "|             Mean             | 11.2 |\n",
      "|             Min              |  2   |\n",
      "|             Max              |  46  |\n",
      "|            Median            | 10.0 |\n",
      "|             Std              | 6.4  |\n",
      "+------------------------------+------+\n",
      "+------------------------------+-------+------+\n",
      "| Treatment duration (in days) | Count |  %   |\n",
      "+------------------------------+-------+------+\n",
      "|             <=5              |   33  | 18.2 |\n",
      "|          5<...<=10           |   69  | 38.1 |\n",
      "|          10<...<=15          |   35  | 19.3 |\n",
      "|          15<...<=20          |   32  | 17.7 |\n",
      "|             >20              |   12  | 6.6  |\n",
      "|           Missing            |   0   | 0.0  |\n",
      "+------------------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now we look at the duration (etalement) of the treatment\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Treatment duration (in days)', '']\n",
    "table.add_row(['Mean', round(data[\"etalement\"].mean(),1)])\n",
    "table.add_row(['Min', data[\"etalement\"].min()])\n",
    "table.add_row(['Max', data[\"etalement\"].max()])\n",
    "table.add_row(['Median', data[\"etalement\"].median()])\n",
    "table.add_row(['Std', round(data[\"etalement\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Treatment duration (in days)', 'Count', '%']\n",
    "table.add_row(['<=5', data[data[\"etalement\"]<=5][\"etalement\"].count(), round(data[data[\"etalement\"]<=5][\"etalement\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['5<...<=10', data[(data[\"etalement\"]>5) & (data[\"etalement\"]<=10)][\"etalement\"].count(), round(data[(data[\"etalement\"]>5) & (data[\"etalement\"]<=10)][\"etalement\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['10<...<=15', data[(data[\"etalement\"]>10) & (data[\"etalement\"]<=15)][\"etalement\"].count(), round(data[(data[\"etalement\"]>10) & (data[\"etalement\"]<=15)][\"etalement\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['15<...<=20', data[(data[\"etalement\"]>15) & (data[\"etalement\"]<=20)][\"etalement\"].count(), round(data[(data[\"etalement\"]>15) & (data[\"etalement\"]<=20)][\"etalement\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['>20', data[data[\"etalement\"]>20][\"etalement\"].count(), round(data[data[\"etalement\"]>20][\"etalement\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['Missing', data['etalement'].isnull().sum(), round(data['etalement'].isnull().sum()/total_nodules*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-------+\n",
      "| Volume of GTV (in cm3) |       |\n",
      "+------------------------+-------+\n",
      "|          Mean          |  6.9  |\n",
      "|          Min           |  0.13 |\n",
      "|          Max           | 51.24 |\n",
      "|         Median         |  3.83 |\n",
      "|          Std           |  8.3  |\n",
      "+------------------------+-------+\n",
      "+------------------------+-------+------+\n",
      "| Volume of GTV (in cm3) | Count |  %   |\n",
      "+------------------------+-------+------+\n",
      "|          <=5           |   99  | 54.7 |\n",
      "|       5<...<=10        |   39  | 21.5 |\n",
      "|          >10           |   35  | 19.3 |\n",
      "|        Missing         |   8   | 4.4  |\n",
      "+------------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now we focus on the vol_GTV (in cm3)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Volume of GTV (in cm3)', '']\n",
    "table.add_row(['Mean', round(data[\"vol_GTV\"].mean(),1)])\n",
    "table.add_row(['Min', data[\"vol_GTV\"].min()])\n",
    "table.add_row(['Max', data[\"vol_GTV\"].max()])\n",
    "table.add_row(['Median', data[\"vol_GTV\"].median()])\n",
    "table.add_row(['Std', round(data[\"vol_GTV\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Volume of GTV (in cm3)', 'Count', '%']\n",
    "table.add_row(['<=5', data[data[\"vol_GTV\"]<=5][\"vol_GTV\"].count(), round(data[data[\"vol_GTV\"]<=5][\"vol_GTV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['5<...<=10', data[(data[\"vol_GTV\"]>5) & (data[\"vol_GTV\"]<=10)][\"vol_GTV\"].count(), round(data[(data[\"vol_GTV\"]>5) & (data[\"vol_GTV\"]<=10)][\"vol_GTV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['>10', data[data[\"vol_GTV\"]>10][\"vol_GTV\"].count(), round(data[data[\"vol_GTV\"]>10][\"vol_GTV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['Missing', data['vol_GTV'].isnull().sum(), round(data['vol_GTV'].isnull().sum()/total_nodules*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-------+\n",
      "| Volume of PTV (in cm3) |       |\n",
      "+------------------------+-------+\n",
      "|          Mean          |  24.2 |\n",
      "|          Min           |  1.79 |\n",
      "|          Max           | 97.21 |\n",
      "|         Median         |  18.1 |\n",
      "|          Std           |  19.8 |\n",
      "+------------------------+-------+\n",
      "+------------------------+-------+------+\n",
      "| Volume of PTV (in cm3) | Count |  %   |\n",
      "+------------------------+-------+------+\n",
      "|          <=10          |   41  | 22.7 |\n",
      "|       10<...<=20       |   46  | 25.4 |\n",
      "|       20<...<=30       |   36  | 19.9 |\n",
      "|          >30           |   40  | 22.1 |\n",
      "|        Missing         |   18  | 9.9  |\n",
      "+------------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now we focus on the vol_PTV (in cm3)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Volume of PTV (in cm3)', '']\n",
    "table.add_row(['Mean', round(data[\"vol_PTV\"].mean(),1)])\n",
    "table.add_row(['Min', data[\"vol_PTV\"].min()])\n",
    "table.add_row(['Max', data[\"vol_PTV\"].max()])\n",
    "table.add_row(['Median', data[\"vol_PTV\"].median()])\n",
    "table.add_row(['Std', round(data[\"vol_PTV\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Volume of PTV (in cm3)', 'Count', '%']\n",
    "table.add_row(['<=10', data[data[\"vol_PTV\"]<=10][\"vol_PTV\"].count(), round(data[data[\"vol_PTV\"]<=10][\"vol_PTV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['10<...<=20', data[(data[\"vol_PTV\"]>10) & (data[\"vol_PTV\"]<=20)][\"vol_PTV\"].count(), round(data[(data[\"vol_PTV\"]>10) & (data[\"vol_PTV\"]<=20)][\"vol_PTV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['20<...<=30', data[(data[\"vol_PTV\"]>20) & (data[\"vol_PTV\"]<=30)][\"vol_PTV\"].count(), round(data[(data[\"vol_PTV\"]>20) & (data[\"vol_PTV\"]<=30)][\"vol_PTV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['>30', data[data[\"vol_PTV\"]>30][\"vol_PTV\"].count(), round(data[data[\"vol_PTV\"]>30][\"vol_PTV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['Missing', data['vol_PTV'].isnull().sum(), round(data['vol_PTV'].isnull().sum()/total_nodules*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-------+\n",
      "| Volume of ITV (in cm3) |       |\n",
      "+------------------------+-------+\n",
      "|          Mean          |  11.5 |\n",
      "|          Min           |  0.59 |\n",
      "|          Max           | 47.25 |\n",
      "|         Median         |  6.98 |\n",
      "|          Std           |  10.8 |\n",
      "+------------------------+-------+\n",
      "+------------------------+-------+------+\n",
      "| Volume of ITV (in cm3) | Count |  %   |\n",
      "+------------------------+-------+------+\n",
      "|          <=5           |   34  | 18.8 |\n",
      "|       5<...<=10        |   26  | 14.4 |\n",
      "|       10<...<=15       |   8   | 4.4  |\n",
      "|          >15           |   27  | 14.9 |\n",
      "|        Missing         |   86  | 47.5 |\n",
      "+------------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now we look at vol_ITV (in cm3)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Volume of ITV (in cm3)', '']\n",
    "table.add_row(['Mean', round(data[\"vol_ITV\"].mean(),1)])\n",
    "table.add_row(['Min', data[\"vol_ITV\"].min()])\n",
    "table.add_row(['Max', data[\"vol_ITV\"].max()])\n",
    "table.add_row(['Median', data[\"vol_ITV\"].median()])\n",
    "table.add_row(['Std', round(data[\"vol_ITV\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Volume of ITV (in cm3)', 'Count', '%']\n",
    "table.add_row(['<=5', data[data[\"vol_ITV\"]<=5][\"vol_ITV\"].count(), round(data[data[\"vol_ITV\"]<=5][\"vol_ITV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['5<...<=10', data[(data[\"vol_ITV\"]>5) & (data[\"vol_ITV\"]<=10)][\"vol_ITV\"].count(), round(data[(data[\"vol_ITV\"]>5) & (data[\"vol_ITV\"]<=10)][\"vol_ITV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['10<...<=15', data[(data[\"vol_ITV\"]>10) & (data[\"vol_ITV\"]<=15)][\"vol_ITV\"].count(), round(data[(data[\"vol_ITV\"]>10) & (data[\"vol_ITV\"]<=15)][\"vol_ITV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['>15', data[data[\"vol_ITV\"]>15][\"vol_ITV\"].count(), round(data[data[\"vol_ITV\"]>15][\"vol_ITV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['Missing', data['vol_ITV'].isnull().sum(), round(data['vol_ITV'].isnull().sum()/total_nodules*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+\n",
      "| Coverage PTV (%) |        |\n",
      "+------------------+--------+\n",
      "|       Mean       |  96.5  |\n",
      "|       Min        |  70.2  |\n",
      "|       Max        | 107.6  |\n",
      "|      Median      | 98.095 |\n",
      "|       Std        |  4.9   |\n",
      "+------------------+--------+\n",
      "+------------------+-------+------+\n",
      "| Coverage PTV (%) | Count |  %   |\n",
      "+------------------+-------+------+\n",
      "|       <=90       |   13  | 7.2  |\n",
      "|    90<...<=95    |   24  | 13.3 |\n",
      "|   95<...<=100    |  140  | 77.3 |\n",
      "|       >100       |   1   | 0.6  |\n",
      "|     Missing      |   3   | 1.7  |\n",
      "+------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Now we look at couv-PTV (%)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Coverage PTV (%)', '']\n",
    "table.add_row(['Mean', round(data[\"couv_PTV\"].mean(),1)])\n",
    "table.add_row(['Min', data[\"couv_PTV\"].min()])\n",
    "table.add_row(['Max', data[\"couv_PTV\"].max()])\n",
    "table.add_row(['Median', data[\"couv_PTV\"].median()])\n",
    "table.add_row(['Std', round(data[\"couv_PTV\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Coverage PTV (%)', 'Count', '%']\n",
    "table.add_row(['<=90', data[data[\"couv_PTV\"]<=90][\"couv_PTV\"].count(), round(data[data[\"couv_PTV\"]<=90][\"couv_PTV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['90<...<=95', data[(data[\"couv_PTV\"]>90) & (data[\"couv_PTV\"]<=95)][\"couv_PTV\"].count(), round(data[(data[\"couv_PTV\"]>90) & (data[\"couv_PTV\"]<=95)][\"couv_PTV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['95<...<=100', data[(data[\"couv_PTV\"]>95) & (data[\"couv_PTV\"]<=100)][\"couv_PTV\"].count(), round(data[(data[\"couv_PTV\"]>95) & (data[\"couv_PTV\"]<=100)][\"couv_PTV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['>100', data[data[\"couv_PTV\"]>100][\"couv_PTV\"].count(), round(data[data[\"couv_PTV\"]>100][\"couv_PTV\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['Missing', data['couv_PTV'].isnull().sum(), round(data['couv_PTV'].isnull().sum()/total_nodules*100,1)])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "| BED_10 (in Gray) |       |\n",
      "+------------------+-------+\n",
      "|       Mean       | 127.4 |\n",
      "|       Min        |  45.0 |\n",
      "|       Max        | 180.0 |\n",
      "|      Median      | 132.0 |\n",
      "|       Std        |  33.2 |\n",
      "+------------------+-------+\n",
      "+------------------+-------+------+\n",
      "| BED_10 (in Gray) | Count |  %   |\n",
      "+------------------+-------+------+\n",
      "|       <=80       |   16  | 8.8  |\n",
      "|   80<...<=100    |   14  | 7.7  |\n",
      "|   100<...<=120   |   55  | 30.4 |\n",
      "|   120<...<=140   |   39  | 21.5 |\n",
      "|       >140       |   57  | 31.5 |\n",
      "|     Missing      |   0   | 0.0  |\n",
      "+------------------+-------+------+\n"
     ]
    }
   ],
   "source": [
    "# Finally we look at BED_10 (in Gray)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['BED_10 (in Gray)', '']\n",
    "table.add_row(['Mean', round(data[\"BED_10\"].mean(),1)])\n",
    "table.add_row(['Min', data[\"BED_10\"].min()])\n",
    "table.add_row(['Max', data[\"BED_10\"].max()])\n",
    "table.add_row(['Median', data[\"BED_10\"].median()])\n",
    "table.add_row(['Std', round(data[\"BED_10\"].std(),1)])\n",
    "print(table)\n",
    "table = PrettyTable()\n",
    "table.field_names = ['BED_10 (in Gray)', 'Count', '%']\n",
    "table.add_row(['<=80', data[data[\"BED_10\"]<=80][\"BED_10\"].count(), round(data[data[\"BED_10\"]<=80][\"BED_10\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['80<...<=100', data[(data[\"BED_10\"]>80) & (data[\"BED_10\"]<=100)][\"BED_10\"].count(), round(data[(data[\"BED_10\"]>80) & (data[\"BED_10\"]<=100)][\"BED_10\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['100<...<=120', data[(data[\"BED_10\"]>100) & (data[\"BED_10\"]<=120)][\"BED_10\"].count(), round(data[(data[\"BED_10\"]>100) & (data[\"BED_10\"]<=120)][\"BED_10\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['120<...<=140', data[(data[\"BED_10\"]>120) & (data[\"BED_10\"]<=140)][\"BED_10\"].count(), round(data[(data[\"BED_10\"]>120) & (data[\"BED_10\"]<=140)][\"BED_10\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['>140', data[data[\"BED_10\"]>140][\"BED_10\"].count(), round(data[data[\"BED_10\"]>140][\"BED_10\"].count()/total_nodules*100,1)])\n",
    "table.add_row(['Missing', data['BED_10'].isnull().sum(), round(data['BED_10'].isnull().sum()/total_nodules*100,1)])\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_lung_response",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
